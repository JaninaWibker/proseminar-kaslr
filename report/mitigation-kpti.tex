A mitigation against many KASLR derandomization attacks is called \textit{Kernel Page Table Isolation} (\textit{KPTI}).
The concept was initially introduced under the name KAISER (\textit{Kernel Address Isolation to have Side-channels Efficiently Removed}) by D. Gruss et al. in \cite{kaiser}.
Originally \textit{KAISER} was implemented as a patch for the Linux kernel and demoed on Ubuntu 16.10.
It was later adapted by the Linux kernel developers and merged into the mainline kernel (4.15) under the name KPTI.

\subsection{The Problem}

The main cause for many KASLR derandomization attacks is improper information leakage after an illegal operation was performed or attempted to be performed by the CPU and not properly rolled back (i.e. caches not being cleared correctly, or timing differences in exception handling, page table traversals and memory accesses).
What all of these attacks rely on is that this initial information is accessed by the CPU and not properly guarded.
If this initial code path leading to the access could be avoided almost all attacks would be rendered unfunctional. \cite{kaiser}

In this case that would mean not mapping the kernel address space into userspace at all and vice-versa, which has been proposed by multiple papers before (Gruss et al. \cite{prefetch-side-channel-smap} and Jang et al. \cite{drk}).

This is a very drastic and brute-force measure which would impact many things such as multithreaded applications or even contexts switches in general making some use cases practically impossible.
Multithreaded applications share the same address space per thread and thus switching to the kernel-only address space would break parallel execution of threads as the user address space would not be accessible anymore.
This would also incur a lot of TLB flushes as the address space would have to be completely switched with every syscall.\cite{kaiser}

Thus a less intrusive approach is needed.

\subsection{The Challenges to overcome}

\textit{D. Gruss et al.} \cite{kaiser} identifies three major challenges that have to be overcome or accomodated for in order for a solution to be viable.

\begin{itemize}
  \item{
    \textbf{Multithreading}:
    Threads share the same address space.
    Thus when a thread enters kernel mode and switches to a kernel-exclusive address space all other threads would switch to the same address space as well, partially defeating the original goal of the mitigation.
    A context switch would also mean having to synchronize all threads.
  }
  \item{
    \textbf{Implicitely assumed and required mappings}:
    Assumptions about the presence of user space mappings being present when in kernel mode and vice-versa are made in many places in the linux kernel.
    These assumptions are often implicit and not easy to spot.
    The architecture of x86 processors requires that a few mappings are present at all times (i.e. when in user space and when in kernel space).
    Changes would have to be made to the kernel at large to accomodate for this, requiring a significant chunk of work.
  }
  \item{
    \textbf{Amount and impact of TLB flushes}:
    Switching the address space incurs an implicit full TLB flush and modifying the address space causes a partial TLB flush. \cite{the-ginormous-intel-manual-volume-3}
  }
\end{itemize}

\subsection{The Approach}

The solution to the given problem by \textit{KAISER} deals with the above challenges.

Split the address space into two parts. First the \textit{Shadow address space} which contains all allocations done in userspace and what is otherwise typically associated with the user space.
Second the \textit{Kernel address space} which contains the kernel code, kernel data and kernel modules.
The kernel address space also has a complete mapping of the user mode space, which is however protected by \textit{SMAP} and \textit{SMEP}.
A few pages are present in both address spaces which are strictly required for the OS to function properly such as the system call trampoline and interrupt descriptor table (\textit{IDT}).

\textit{SMAP} and \textit{SMEP} stand for \textit{Supervisor Mode Access Prevention} and \textit{Supervisor Mode Execution Prevention} respectively.
The MMU restricts accesses originating from the kernel to user-accessible memory.
This is to prevent the kernel from unintentionally executing (or writing to) user space memory.

Whenever a system call occurs in user mode the address space is switched from the shadow address space to the kernel address space.
As each core has its own \textit{CR3}-register (the entrypoint to the currently active page table).
Thus this behaviour solves the multithreading challenge as no two threads can be executed on the same core at the same time with one being in kernel mode while the other is not, which would lead to the same address space being used by both allowing for microarchitectural flaws to be exploited.

To implement switching between the address spaces with as little overhead as possible there needs to be a way to distinguish between them and get the address of the respective other address space using only the \textit{CR3}-register and very little computation.
This is done by enforcing a strict placement of the PML4 page table, which is the top-most and thus entrypoint to the page table hierarchy, such that a single bit encodes the address space in use.
The 12th bit in the address is chosen for this purpose.
A \lstinline{0} refers to the kernel address space and a \lstinline{1} to the shadow address space.
Simple bit manipulation allows computing the address of the other address space and determining which address space is active.

Memory overhead introduced by this is small: 8KB per thread, 12KB per process and 1 MB globally in the kernel.

\textbf{TODO}
